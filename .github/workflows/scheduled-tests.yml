name: Scheduled Tests

on:
  workflow_dispatch:  # Manual trigger only
  # schedule:
  #   # Run tests every day at 2 AM UTC
  #   - cron: '0 2 * * *'

jobs:
  full-test-suite:
    name: Full Test Suite (Nightly)
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.13'
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt

    - name: Run all tests including slow tests
      run: |
        python -m pytest tests/ -v \
          --cov=src \
          --cov-report=xml \
          --cov-report=html \
          --cov-report=term-missing \
          --durations=10

    - name: Generate detailed report
      run: |
        python -m pytest tests/ --collect-only -q > test-inventory.txt
        coverage report > coverage-report.txt

    - name: Upload reports
      uses: actions/upload-artifact@v4
      with:
        name: nightly-test-reports
        path: |
          htmlcov/
          coverage.xml
          test-inventory.txt
          coverage-report.txt

    - name: Check for test regressions
      run: |
        # Check if any previously passing tests are now failing
        FAILED=$(python -m pytest tests/ --tb=line | grep -c "FAILED" || echo "0")
        if [ "$FAILED" -gt 3 ]; then
          echo "âš ï¸ More than 3 tests failing in nightly run!"
          echo "Current failing tests: $FAILED"
          echo "Expected maximum: 3"
          exit 1
        fi

    - name: Create issue on failure
      if: failure()
      uses: actions/github-script@v7
      with:
        script: |
          github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: 'ðŸš¨ Nightly Test Failure',
            body: `The scheduled nightly test run has failed.

            **Run Details:**
            - Workflow: ${{ github.workflow }}
            - Run ID: ${{ github.run_id }}
            - Date: ${new Date().toISOString()}

            **Action Required:**
            Please check the workflow logs and fix any failing tests.

            [View Workflow Run](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})`,
            labels: ['bug', 'tests', 'automated']
          });

  dependency-check:
    name: Check for Dependency Updates
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.13'

    - name: Check for outdated packages
      run: |
        python -m pip install --upgrade pip
        pip install pip-audit
        pip list --outdated > outdated-packages.txt || true
        cat outdated-packages.txt

    - name: Run security audit
      run: |
        pip-audit --output audit-report.json --format json || true

    - name: Upload audit results
      uses: actions/upload-artifact@v4
      with:
        name: dependency-audit
        path: |
          outdated-packages.txt
          audit-report.json

  performance-benchmark:
    name: Performance Benchmarks
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.13'
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt
        pip install pytest-benchmark

    - name: Run benchmark tests
      run: |
        # Run tests with benchmark plugin (if you have benchmark tests)
        python -m pytest tests/ -v --benchmark-only || echo "No benchmark tests found"

    - name: Upload benchmark results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: benchmark-results
        path: .benchmarks/
